### Example Ontology Evaluation Criteria and Strategies

Computational ontologies are key to information retrieval, semantic integration of datasets, and semantic similarity analyses. It's sometimes a challenge to find a self-contained material where you can find "what" to evaluate after you've designed an ontology, and "how" to do it. Here you may find a start. Depending on the use case, and the intended audience, it may be interesting to evaluate design aspects, or implementation aspects, or both. 



### *Design: support human reasoning*
---

* Accuracy (correct representation of aspects of the real world)

* Adaptability (ease of performing changes) 

* Clarity (effective communication of the intended meaning of defined terms)

* Cognitive adequacy (match between formal and cognitive semantics)

* Completeness (appropriate coverage of the domain of interest)

* Conciseness (absence of unnecessary or useless definitions or axioms)

* Consistency (incapacity of getting contradictory conclusions from valid input data)

* Expressiveness (number of competency questions that the ontology can answer)

* Grounding (number of assumptions done by the ontology’s underlying philosophical theory about reality)




### *Implementation: support automated reasoning*
---

* Computational efficiency (ease and speed of processing by reasoners)

* Congruency (fitness between ontology and corpus terms)

* Practical usefulness (number of practical problems to which the ontology can be applied)

* Precision (fraction of retrieved instances by the ontology that are relevant)

* Recall (fraction of relevant instances that are retrieved by the ontology)






The list will be extended with strategies as I become aware of them. Reference: Degbelo, A. (2017). A snapshot of ontology evaluation criteria and strategies. In R. Hoestra, C. Faron-Zucker, T. Pellegrini, & V. de Boer (Eds.), Proceedings of the 13th International Conference on Semantic Systems - SEMANTICS 2017 (pp. 1–8). https://doi.org/10.1145/3132218.3132219


